{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7381069,"sourceType":"datasetVersion","datasetId":4289492}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -Uqq git+https://github.com/fastai/course22p2","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:10:25.580932Z","iopub.execute_input":"2024-01-11T16:10:25.581402Z","iopub.status.idle":"2024-01-11T16:10:53.710966Z","shell.execute_reply.started":"2024-01-11T16:10:25.581366Z","shell.execute_reply":"2024-01-11T16:10:53.709374Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#| default_exp training","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:10:53.713654Z","iopub.execute_input":"2024-01-11T16:10:53.714015Z","iopub.status.idle":"2024-01-11T16:10:53.719847Z","shell.execute_reply.started":"2024-01-11T16:10:53.713986Z","shell.execute_reply":"2024-01-11T16:10:53.718658Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#|export\nimport pickle, gzip, math, os, time, shutil\nfrom pathlib import Path\nimport numpy as np\n\nimport matplotlib as mpl, matplotlib.pyplot as plt\n\nimport torch\nfrom torch import tensor,nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:10:53.721998Z","iopub.execute_input":"2024-01-11T16:10:53.722484Z","iopub.status.idle":"2024-01-11T16:10:55.581691Z","shell.execute_reply.started":"2024-01-11T16:10:53.722438Z","shell.execute_reply":"2024-01-11T16:10:55.580472Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from fastcore.test import test_close\n\ntorch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\ntorch.manual_seed(1)\nmpl.rcParams['image.cmap'] = 'gray'\n\npath_data = Path('/kaggle/input/mnist-data')\npath_gz = path_data/'mnist.pkl'\nwith open(path_gz, 'rb') as f:\n    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n\nx_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])\nx_train.shape, y_train.shape, x_valid.shape, y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:10:55.584630Z","iopub.execute_input":"2024-01-11T16:10:55.585282Z","iopub.status.idle":"2024-01-11T16:10:57.870993Z","shell.execute_reply.started":"2024-01-11T16:10:55.585233Z","shell.execute_reply":"2024-01-11T16:10:57.869736Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(torch.Size([50000, 784]),\n torch.Size([50000]),\n torch.Size([10000, 784]),\n torch.Size([10000]))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Initial setup","metadata":{}},{"cell_type":"markdown","source":"### Data","metadata":{}},{"cell_type":"code","source":"# Extract shapes and other parameters\nnum_samples, num_features = x_train.shape\nnum_classes = y_train.max() + 1\nhidden_units = 50","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:11:18.429927Z","iopub.execute_input":"2024-01-11T16:11:18.431121Z","iopub.status.idle":"2024-01-11T16:11:18.456617Z","shell.execute_reply.started":"2024-01-11T16:11:18.431061Z","shell.execute_reply":"2024-01-11T16:11:18.455355Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        self.layers = [\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, output_size)\n        ]\n        \n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:11:22.906354Z","iopub.execute_input":"2024-01-11T16:11:22.906839Z","iopub.status.idle":"2024-01-11T16:11:22.915315Z","shell.execute_reply.started":"2024-01-11T16:11:22.906798Z","shell.execute_reply":"2024-01-11T16:11:22.914005Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"input_size = num_features  \nhidden_size = hidden_units\noutput_size = num_classes  \n\n# Instantiate the CustomModel\ncustom_model = CustomModel(input_size, hidden_size, output_size)\n\n# Forward pass to get predictions\npredictions = custom_model(torch.Tensor(x_train))\n\n# Print the shape of the predictions\nprint(\"Shape of predictions:\", predictions.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:11:34.265429Z","iopub.execute_input":"2024-01-11T16:11:34.266212Z","iopub.status.idle":"2024-01-11T16:11:34.384229Z","shell.execute_reply.started":"2024-01-11T16:11:34.266168Z","shell.execute_reply":"2024-01-11T16:11:34.383403Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Shape of predictions: torch.Size([50000, 10])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Cross entropy loss","metadata":{}},{"cell_type":"markdown","source":"First, we will need to compute the softmax of our activations. This is defined by:\n\n$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n\nor more concisely:\n\n$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum\\limits_{0 \\leq j \\lt n} e^{x_{j}}}$$ \n\nIn practice, we will need the log of the softmax when we calculate the loss.","metadata":{}},{"cell_type":"code","source":"def calculate_log_softmax(x):\n    exp_x = x.exp()\n    softmax_x = exp_x / exp_x.sum(-1, keepdim=True)\n    log_softmax_x = softmax_x.log()\n    return log_softmax_x","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:12:42.305482Z","iopub.execute_input":"2024-01-11T16:12:42.305934Z","iopub.status.idle":"2024-01-11T16:12:42.311791Z","shell.execute_reply.started":"2024-01-11T16:12:42.305902Z","shell.execute_reply":"2024-01-11T16:12:42.310804Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"log_softmax_predictions = calculate_log_softmax(predictions)\nlog_softmax_predictions\n\n# Print the shape of the log-softmax predictions\n# print(\"Shape of log-softmax predictions:\", log_softmax_predictions.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:12:47.071011Z","iopub.execute_input":"2024-01-11T16:12:47.071483Z","iopub.status.idle":"2024-01-11T16:12:47.122402Z","shell.execute_reply.started":"2024-01-11T16:12:47.071449Z","shell.execute_reply":"2024-01-11T16:12:47.121442Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n        ...,\n        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<LogBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"Note that the formula \n\n$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$ \n\ngives a simplification when we compute the log softmax:","metadata":{}},{"cell_type":"code","source":"def calculate_log_softmax(x):\n    log_softmax_x = x - x.exp().sum(-1, keepdim=True).log()\n    return log_softmax_x\n\n# Assuming 'predictions' is the variable from the previous responses\nlog_softmax_predictions = calculate_log_softmax(predictions)\nlog_softmax_predictions\n\n# Print the shape of the log-softmax predictions\n# print(\"Shape of log-softmax predictions:\", log_softmax_predictions.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:13:00.931811Z","iopub.execute_input":"2024-01-11T16:13:00.932721Z","iopub.status.idle":"2024-01-11T16:13:00.946440Z","shell.execute_reply.started":"2024-01-11T16:13:00.932675Z","shell.execute_reply":"2024-01-11T16:13:00.945219Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n        ...,\n        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the [LogSumExp trick](https://en.wikipedia.org/wiki/LogSumExp). The idea is to use the following formula:\n\n$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n\nwhere a is the maximum of the $x_{j}$.","metadata":{}},{"cell_type":"code","source":"def calculate_logsumexp(x):\n    max_values = x.max(-1)[0]\n    logsumexp_x = max_values + (x - max_values[:, None]).exp().sum(-1).log()\n    return logsumexp_x\n\nlogsumexp_predictions = calculate_logsumexp(predictions)\nlogsumexp_predictions\n\n# Print the shape of the logsumexp predictions\n# print(\"Shape of logsumexp predictions:\", logsumexp_predictions.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:13:51.073134Z","iopub.execute_input":"2024-01-11T16:13:51.073610Z","iopub.status.idle":"2024-01-11T16:13:51.089255Z","shell.execute_reply.started":"2024-01-11T16:13:51.073572Z","shell.execute_reply":"2024-01-11T16:13:51.087959Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"tensor([2.28, 2.30, 2.29,  ..., 2.30, 2.28, 2.30], grad_fn=<AddBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us. ","metadata":{}},{"cell_type":"code","source":"def calculate_log_softmax(x):\n    log_softmax_x = x - x.logsumexp(-1, keepdim=True)\n    return log_softmax_x\n\nlog_softmax_predictions = calculate_log_softmax(predictions)\nlog_softmax_predictions\n\n# Print the shape of the log-softmax predictions\n# print(\"Shape of log-softmax predictions:\", log_softmax_predictions.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:14:24.908447Z","iopub.execute_input":"2024-01-11T16:14:24.908867Z","iopub.status.idle":"2024-01-11T16:14:24.927008Z","shell.execute_reply.started":"2024-01-11T16:14:24.908835Z","shell.execute_reply":"2024-01-11T16:14:24.925961Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n        ...,\n        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.testing\n\n# Define the logsumexp function\ndef logsumexp(x):\n    m = x.max(-1)[0]\n    return m + (x - m[:, None]).exp().sum(-1).log()\n\n# Calculate logsumexp(predictions)\ncalculated_logsumexp = logsumexp(predictions)\n\n# Check if logsumexp(predictions) is close to predictions.logsumexp(-1)\ntorch.testing.assert_close(calculated_logsumexp, predictions.logsumexp(-1))\n\n# Calculate log softmax of pred\ncalculated_log_softmax = calculate_log_softmax(predictions)\n\n# Print the result\nprint(\"Log softmax of 'pred':\", calculated_log_softmax)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:14:50.362700Z","iopub.execute_input":"2024-01-11T16:14:50.363185Z","iopub.status.idle":"2024-01-11T16:14:50.388939Z","shell.execute_reply.started":"2024-01-11T16:14:50.363148Z","shell.execute_reply":"2024-01-11T16:14:50.387766Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Log softmax of 'pred': tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n        ...,\n        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n\n$$ -\\sum x\\, \\log p(x) $$\n\nBut since our $x$s are 1-hot encoded (actually, they're just the integer indices), this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target.\n\nThis can be done using numpy-style [integer array indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#integer-array-indexing). Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link.","metadata":{}},{"cell_type":"code","source":"y_train[:3]","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:16:08.494655Z","iopub.execute_input":"2024-01-11T16:16:08.495097Z","iopub.status.idle":"2024-01-11T16:16:08.504700Z","shell.execute_reply.started":"2024-01-11T16:16:08.495067Z","shell.execute_reply":"2024-01-11T16:16:08.503160Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"tensor([5, 0, 4])"},"metadata":{}}]},{"cell_type":"code","source":"calculated_log_softmax[0,5], calculated_log_softmax[1,0], calculated_log_softmax[2,4]","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:16:09.847439Z","iopub.execute_input":"2024-01-11T16:16:09.847854Z","iopub.status.idle":"2024-01-11T16:16:09.859104Z","shell.execute_reply.started":"2024-01-11T16:16:09.847825Z","shell.execute_reply":"2024-01-11T16:16:09.857869Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(tensor(-2.20, grad_fn=<SelectBackward0>),\n tensor(-2.37, grad_fn=<SelectBackward0>),\n tensor(-2.36, grad_fn=<SelectBackward0>))"},"metadata":{}}]},{"cell_type":"code","source":"calculated_log_softmax[[0,1,2], y_train[:3]]","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:16:10.337275Z","iopub.execute_input":"2024-01-11T16:16:10.338511Z","iopub.status.idle":"2024-01-11T16:16:10.350870Z","shell.execute_reply.started":"2024-01-11T16:16:10.338462Z","shell.execute_reply":"2024-01-11T16:16:10.349424Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([-2.20, -2.37, -2.36], grad_fn=<IndexBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"# Define the negative log likelihood (nll) function\ndef nll(inputs, targets):\n    \"\"\"\n    the nll function calculates the negative log \n    likelihood given the input (predictions) and target (ground truth labels).\n    \"\"\"\n    return -inputs[range(targets.shape[0]), targets].mean()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:16:11.055006Z","iopub.execute_input":"2024-01-11T16:16:11.055597Z","iopub.status.idle":"2024-01-11T16:16:11.061632Z","shell.execute_reply.started":"2024-01-11T16:16:11.055559Z","shell.execute_reply":"2024-01-11T16:16:11.060647Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Calculate the negative log likelihood\nnegative_log_likelihood_loss = nll(calculated_log_softmax, y_train)\nnegative_log_likelihood_loss","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:16:25.212477Z","iopub.execute_input":"2024-01-11T16:16:25.212900Z","iopub.status.idle":"2024-01-11T16:16:25.249359Z","shell.execute_reply.started":"2024-01-11T16:16:25.212870Z","shell.execute_reply":"2024-01-11T16:16:25.248509Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"tensor(2.30, grad_fn=<NegBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"Then use PyTorch's implementation.","metadata":{}},{"cell_type":"code","source":"test_close(F.nll_loss(F.log_softmax(predictions, -1), y_train), negative_log_likelihood_loss, 1e-3)\n\n# error_rate = F.nll_loss(F.log_softmax(predictions, -1), y_train)\n# torch.testing.assert_close(error_rate, negative_log_likelihood_loss)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:16:34.812264Z","iopub.execute_input":"2024-01-11T16:16:34.812770Z","iopub.status.idle":"2024-01-11T16:16:34.832072Z","shell.execute_reply.started":"2024-01-11T16:16:34.812729Z","shell.execute_reply":"2024-01-11T16:16:34.830939Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`.","metadata":{}},{"cell_type":"code","source":"test_close(F.cross_entropy(predictions, y_train), negative_log_likelihood_loss, 1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:16:47.510504Z","iopub.execute_input":"2024-01-11T16:16:47.510985Z","iopub.status.idle":"2024-01-11T16:16:47.520797Z","shell.execute_reply.started":"2024-01-11T16:16:47.510952Z","shell.execute_reply":"2024-01-11T16:16:47.519513Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Basic training loop","metadata":{}},{"cell_type":"markdown","source":"Basically the training loop repeats over the following steps:\n- get the output of the model on a batch of inputs\n- compare the output to the labels we have and compute a loss\n- calculate the gradients of the loss with respect to every parameter of the model\n- update said parameters with those gradients to make them a little bit better","metadata":{}},{"cell_type":"code","source":"# Define the loss function (cross entropy)\ncross_entropy_loss_func = F.cross_entropy","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:16:58.057079Z","iopub.execute_input":"2024-01-11T16:16:58.057551Z","iopub.status.idle":"2024-01-11T16:16:58.062665Z","shell.execute_reply.started":"2024-01-11T16:16:58.057515Z","shell.execute_reply":"2024-01-11T16:16:58.061404Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Set batch size\nbatch_size = 50\n\n# Create a mini-batch from x_train\nmini_batch = x_train[:batch_size]\n\n# Make predictions using the custom model\nwith torch.no_grad():\n    predictions = custom_model(torch.Tensor(mini_batch))\n\n# Print the first prediction and the shape of the predictions\nprint(\"First prediction:\", predictions[0])\nprint(\"Shape of predictions:\", predictions.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:17:27.172179Z","iopub.execute_input":"2024-01-11T16:17:27.173438Z","iopub.status.idle":"2024-01-11T16:17:27.190245Z","shell.execute_reply.started":"2024-01-11T16:17:27.173380Z","shell.execute_reply":"2024-01-11T16:17:27.188908Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"First prediction: tensor([-0.09, -0.21, -0.08,  0.10, -0.04,  0.08, -0.04, -0.03,  0.01,  0.06])\nShape of predictions: torch.Size([50, 10])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract labels for the mini-batch\nmini_batch_labels = y_train[:batch_size]\n\n# Print the labels for the mini-batch\nprint(\"Labels for the mini-batch:\", mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:17:45.471395Z","iopub.execute_input":"2024-01-11T16:17:45.471860Z","iopub.status.idle":"2024-01-11T16:17:45.479435Z","shell.execute_reply.started":"2024-01-11T16:17:45.471824Z","shell.execute_reply":"2024-01-11T16:17:45.478307Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Labels for the mini-batch: tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n        3, 9, 8, 5, 9, 3])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the loss\nloss = cross_entropy_loss_func(predictions, mini_batch_labels)\nloss","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:17:54.377406Z","iopub.execute_input":"2024-01-11T16:17:54.377872Z","iopub.status.idle":"2024-01-11T16:17:54.386392Z","shell.execute_reply.started":"2024-01-11T16:17:54.377838Z","shell.execute_reply":"2024-01-11T16:17:54.384856Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"tensor(2.30)"},"metadata":{}}]},{"cell_type":"code","source":"predictions.argmax(dim=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:18:01.341011Z","iopub.execute_input":"2024-01-11T16:18:01.341467Z","iopub.status.idle":"2024-01-11T16:18:01.349464Z","shell.execute_reply.started":"2024-01-11T16:18:01.341432Z","shell.execute_reply":"2024-01-11T16:18:01.347840Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3, 9, 3, 5, 3, 8,\n        3, 5, 9, 5, 9, 5])"},"metadata":{}}]},{"cell_type":"code","source":"#|export\ndef accuracy(predictions, ground_truth_labels):\n    correct_predictions = (predictions.argmax(dim=1) == ground_truth_labels).float()\n    accuracy_value = correct_predictions.mean()\n    return accuracy_value\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:18:50.433086Z","iopub.execute_input":"2024-01-11T16:18:50.433583Z","iopub.status.idle":"2024-01-11T16:18:50.439713Z","shell.execute_reply.started":"2024-01-11T16:18:50.433545Z","shell.execute_reply":"2024-01-11T16:18:50.438523Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"accuracy(predictions, mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:18:54.014301Z","iopub.execute_input":"2024-01-11T16:18:54.014782Z","iopub.status.idle":"2024-01-11T16:18:54.023545Z","shell.execute_reply.started":"2024-01-11T16:18:54.014745Z","shell.execute_reply":"2024-01-11T16:18:54.022352Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"tensor(0.08)"},"metadata":{}}]},{"cell_type":"code","source":"# Define learning rate and number of epochs\nlearning_rate = 0.5\nnum_epochs = 3","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:18:57.677935Z","iopub.execute_input":"2024-01-11T16:18:57.678390Z","iopub.status.idle":"2024-01-11T16:18:57.684327Z","shell.execute_reply.started":"2024-01-11T16:18:57.678330Z","shell.execute_reply":"2024-01-11T16:18:57.683128Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#|export\ndef report_metrics(loss, predictions, ground_truth_labels):\n    accuracy_value = accuracy(predictions, ground_truth_labels)\n    print(f'Loss: {loss:.2f}, Accuracy: {accuracy_value:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:19:11.388179Z","iopub.execute_input":"2024-01-11T16:19:11.388646Z","iopub.status.idle":"2024-01-11T16:19:11.394684Z","shell.execute_reply.started":"2024-01-11T16:19:11.388612Z","shell.execute_reply":"2024-01-11T16:19:11.393240Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Create a mini-batch from x_train and corresponding labels\nmini_batch_data = x_train[:batch_size]\nmini_batch_labels = y_train[:batch_size]\n\npredictions = custom_model(torch.Tensor(mini_batch_data))\n\n# Calculate the loss using the loss function\nloss_value = cross_entropy_loss_func(predictions, mini_batch_labels)\n\n# Report metrics\nreport_metrics(loss_value.item(), predictions, mini_batch_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:19:33.605887Z","iopub.execute_input":"2024-01-11T16:19:33.606964Z","iopub.status.idle":"2024-01-11T16:19:33.615362Z","shell.execute_reply.started":"2024-01-11T16:19:33.606921Z","shell.execute_reply":"2024-01-11T16:19:33.614175Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Loss: 2.30, Accuracy: 0.08\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loop through epochs\nfor epoch in range(num_epochs):\n    # Loop through mini-batches\n    for i in range(0, num_samples, batch_size):\n        # Create a slice for the current mini-batch\n        current_slice = slice(i, min(num_samples, i + batch_size))\n        \n        # Extract the mini-batch data and labels\n        mini_batch_data, mini_batch_labels = x_train[current_slice], y_train[current_slice]\n        \n        # Make predictions using the model\n        predictions = custom_model(torch.Tensor(mini_batch_data))\n        \n        # Calculate the loss using the loss function\n        loss_value = cross_entropy_loss_func(predictions, mini_batch_labels)\n        \n        # Backpropagation\n        loss_value.backward()\n        \n        # Update model parameters using gradient descent\n        with torch.no_grad():\n            for layer in custom_model.layers:\n                if hasattr(layer, 'weight'):\n                    layer.weight -= layer.weight.grad * learning_rate\n                    layer.bias -= layer.bias.grad * learning_rate\n                    layer.weight.grad.zero_()\n                    layer.bias.grad.zero_()\n    \n    # Report metrics for the last mini-batch in the epoch\n    report_metrics(loss_value.item(), predictions, mini_batch_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:23:04.655374Z","iopub.execute_input":"2024-01-11T16:23:04.655872Z","iopub.status.idle":"2024-01-11T16:23:06.626931Z","shell.execute_reply.started":"2024-01-11T16:23:04.655833Z","shell.execute_reply":"2024-01-11T16:23:06.625785Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Loss: 0.11, Accuracy: 0.96\nLoss: 0.13, Accuracy: 0.96\nLoss: 0.10, Accuracy: 0.96\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Using parameters and optim","metadata":{}},{"cell_type":"markdown","source":"### Parameters","metadata":{}},{"cell_type":"code","source":"module1 = nn.Module()\nmodule1.foo = nn.Linear(3,4)\nmodule1","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:23:15.837726Z","iopub.execute_input":"2024-01-11T16:23:15.838151Z","iopub.status.idle":"2024-01-11T16:23:15.847429Z","shell.execute_reply.started":"2024-01-11T16:23:15.838120Z","shell.execute_reply":"2024-01-11T16:23:15.845894Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Module(\n  (foo): Linear(in_features=3, out_features=4, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"list(module1.named_children())","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:23:18.273913Z","iopub.execute_input":"2024-01-11T16:23:18.274467Z","iopub.status.idle":"2024-01-11T16:23:18.282503Z","shell.execute_reply.started":"2024-01-11T16:23:18.274425Z","shell.execute_reply":"2024-01-11T16:23:18.281294Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[('foo', Linear(in_features=3, out_features=4, bias=True))]"},"metadata":{}}]},{"cell_type":"code","source":"module1.named_children()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:23:31.482852Z","iopub.execute_input":"2024-01-11T16:23:31.483303Z","iopub.status.idle":"2024-01-11T16:23:31.491329Z","shell.execute_reply.started":"2024-01-11T16:23:31.483267Z","shell.execute_reply":"2024-01-11T16:23:31.490443Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<generator object Module.named_children at 0x7bec643076f0>"},"metadata":{}}]},{"cell_type":"code","source":"list(module1.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:23:32.828573Z","iopub.execute_input":"2024-01-11T16:23:32.829730Z","iopub.status.idle":"2024-01-11T16:23:32.838268Z","shell.execute_reply.started":"2024-01-11T16:23:32.829687Z","shell.execute_reply":"2024-01-11T16:23:32.837230Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[Parameter containing:\n tensor([[ 0.57,  0.43, -0.30],\n         [ 0.13, -0.32, -0.24],\n         [ 0.51,  0.04,  0.22],\n         [ 0.13, -0.17, -0.24]], requires_grad=True),\n Parameter containing:\n tensor([-0.01, -0.51, -0.39,  0.56], requires_grad=True)]"},"metadata":{}}]},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, num_input_features, num_hidden_units, num_output_classes):\n        super().__init__()\n        self.layer1 = nn.Linear(num_input_features, num_hidden_units)\n        self.layer2 = nn.Linear(num_hidden_units, num_output_classes)\n        self.activation_function = nn.ReLU()\n    \n    def forward(self, inputs):\n        intermediate_representation = self.activation_function(self.layer1(inputs))\n        outputs = self.layer2(intermediate_representation)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:24:29.175361Z","iopub.execute_input":"2024-01-11T16:24:29.175783Z","iopub.status.idle":"2024-01-11T16:24:29.184489Z","shell.execute_reply.started":"2024-01-11T16:24:29.175753Z","shell.execute_reply":"2024-01-11T16:24:29.182995Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model = MLP(num_features, hidden_units, 10)\nmodel.layer1","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:24:32.534927Z","iopub.execute_input":"2024-01-11T16:24:32.535360Z","iopub.status.idle":"2024-01-11T16:24:32.544186Z","shell.execute_reply.started":"2024-01-11T16:24:32.535313Z","shell.execute_reply":"2024-01-11T16:24:32.542887Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"Linear(in_features=784, out_features=50, bias=True)"},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:24:38.163366Z","iopub.execute_input":"2024-01-11T16:24:38.163818Z","iopub.status.idle":"2024-01-11T16:24:38.172587Z","shell.execute_reply.started":"2024-01-11T16:24:38.163787Z","shell.execute_reply":"2024-01-11T16:24:38.171379Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"MLP(\n  (layer1): Linear(in_features=784, out_features=50, bias=True)\n  (layer2): Linear(in_features=50, out_features=10, bias=True)\n  (activation_function): ReLU()\n)"},"metadata":{}}]},{"cell_type":"code","source":"for name, child_module in model.named_children():\n    print(f\"{name}: {child_module}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:24:51.151578Z","iopub.execute_input":"2024-01-11T16:24:51.152666Z","iopub.status.idle":"2024-01-11T16:24:51.157949Z","shell.execute_reply.started":"2024-01-11T16:24:51.152623Z","shell.execute_reply":"2024-01-11T16:24:51.157187Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"layer1: Linear(in_features=784, out_features=50, bias=True)\nlayer2: Linear(in_features=50, out_features=10, bias=True)\nactivation_function: ReLU()\n","output_type":"stream"}]},{"cell_type":"code","source":"for parameters in model.parameters():\n    print(parameters.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:26:07.543625Z","iopub.execute_input":"2024-01-11T16:26:07.544052Z","iopub.status.idle":"2024-01-11T16:26:07.550405Z","shell.execute_reply.started":"2024-01-11T16:26:07.544021Z","shell.execute_reply":"2024-01-11T16:26:07.549233Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"torch.Size([50, 784])\ntorch.Size([50])\ntorch.Size([10, 50])\ntorch.Size([10])\n","output_type":"stream"}]},{"cell_type":"code","source":"def fit():\n    # Loop through epochs\n    for epoch in range(num_epochs):\n        # Loop through mini-batches\n        for i in range(0, num_samples, batch_size):\n            # Create a slice for the current mini-batch\n            current_slice = slice(i, min(num_samples, i + batch_size))\n\n            # Extract the mini-batch data and labels\n            mini_batch_data, mini_batch_labels = x_train[current_slice], y_train[current_slice]\n\n            # Make predictions using the model\n            predictions = model(torch.Tensor(mini_batch_data))\n\n            # Calculate the loss using the loss function\n            loss_value = cross_entropy_loss_func(predictions, mini_batch_labels)\n\n            # Backpropagation\n            loss_value.backward()\n\n            # Update model parameters using gradient descent\n            with torch.no_grad():\n                for parameter in model.parameters():\n                    parameter -= parameter.grad * learning_rate\n                model.zero_grad()\n\n        # Report metrics for the last mini-batch in the epoch\n        report_metrics(loss_value.item(), predictions, mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:26:25.089749Z","iopub.execute_input":"2024-01-11T16:26:25.090215Z","iopub.status.idle":"2024-01-11T16:26:25.099065Z","shell.execute_reply.started":"2024-01-11T16:26:25.090176Z","shell.execute_reply":"2024-01-11T16:26:25.097756Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"fit()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:26:25.582641Z","iopub.execute_input":"2024-01-11T16:26:25.583701Z","iopub.status.idle":"2024-01-11T16:26:27.907648Z","shell.execute_reply.started":"2024-01-11T16:26:25.583653Z","shell.execute_reply":"2024-01-11T16:26:27.906533Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Loss: 0.19, Accuracy: 0.96\nLoss: 0.11, Accuracy: 0.96\nLoss: 0.04, Accuracy: 1.00\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Behind the scenes, PyTorch overrides the `__setattr__` function in `nn.Module` so that the submodules you define are properly registered as parameters of the model.","metadata":{}},{"cell_type":"code","source":"class MyModule:\n    def __init__(self, num_input_features, num_hidden_units, num_output_classes):\n        self._components = {}\n        self.linear_layer_1 = nn.Linear(num_input_features, num_hidden_units)\n        self.linear_layer_2 = nn.Linear(num_hidden_units, num_output_classes)\n\n    def __setattr__(self, key, value):\n        if not key.startswith(\"_\"):\n            self._components[key] = value\n        super().__setattr__(key, value)\n\n    def __repr__(self):\n        return str(self._components)\n\n    def parameters(self):\n        for layer in self._components.values():\n            yield from layer.parameters()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:30:14.882618Z","iopub.execute_input":"2024-01-11T16:30:14.883096Z","iopub.status.idle":"2024-01-11T16:30:14.891837Z","shell.execute_reply.started":"2024-01-11T16:30:14.883063Z","shell.execute_reply":"2024-01-11T16:30:14.890762Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"mdl = MyModule(num_features, hidden_units, 10)\nmdl","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:30:15.251427Z","iopub.execute_input":"2024-01-11T16:30:15.252082Z","iopub.status.idle":"2024-01-11T16:30:15.260158Z","shell.execute_reply.started":"2024-01-11T16:30:15.252047Z","shell.execute_reply":"2024-01-11T16:30:15.259044Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"{'linear_layer_1': Linear(in_features=784, out_features=50, bias=True), 'linear_layer_2': Linear(in_features=50, out_features=10, bias=True)}"},"metadata":{}}]},{"cell_type":"code","source":"for parameters in mdl.parameters():\n    print(parameters.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:30:25.594565Z","iopub.execute_input":"2024-01-11T16:30:25.595027Z","iopub.status.idle":"2024-01-11T16:30:25.601952Z","shell.execute_reply.started":"2024-01-11T16:30:25.594988Z","shell.execute_reply":"2024-01-11T16:30:25.600567Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"torch.Size([50, 784])\ntorch.Size([50])\ntorch.Size([10, 50])\ntorch.Size([10])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Registering modules","metadata":{}},{"cell_type":"code","source":"from functools import reduce","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:32:48.753095Z","iopub.execute_input":"2024-01-11T16:32:48.753604Z","iopub.status.idle":"2024-01-11T16:32:48.759505Z","shell.execute_reply.started":"2024-01-11T16:32:48.753568Z","shell.execute_reply":"2024-01-11T16:32:48.758128Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"We can use the original `layers` approach, but we have to register the modules.","metadata":{}},{"cell_type":"code","source":"layers = [nn.Linear(num_features, hidden_units), nn.ReLU(), nn.Linear(hidden_units,10)]","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:32:54.281026Z","iopub.execute_input":"2024-01-11T16:32:54.281474Z","iopub.status.idle":"2024-01-11T16:32:54.288795Z","shell.execute_reply.started":"2024-01-11T16:32:54.281440Z","shell.execute_reply":"2024-01-11T16:32:54.287219Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, layers):\n        super().__init__()\n        self.layer_sequence = layers\n        for idx, layer in enumerate(self.layer_sequence):\n            self.add_module(f'layer_{idx}', layer)\n\n    def forward(self, input_tensor):\n        return reduce(lambda val, layer: layer(val), self.layer_sequence, input_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:34:07.333935Z","iopub.execute_input":"2024-01-11T16:34:07.334509Z","iopub.status.idle":"2024-01-11T16:34:07.342033Z","shell.execute_reply.started":"2024-01-11T16:34:07.334464Z","shell.execute_reply":"2024-01-11T16:34:07.340786Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"model = Model(layers)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:34:10.775004Z","iopub.execute_input":"2024-01-11T16:34:10.775980Z","iopub.status.idle":"2024-01-11T16:34:10.784762Z","shell.execute_reply.started":"2024-01-11T16:34:10.775925Z","shell.execute_reply":"2024-01-11T16:34:10.783645Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"Model(\n  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n  (layer_1): ReLU()\n  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model(mini_batch_data).shape","metadata":{"execution":{"iopub.status.busy":"2024-01-11T10:19:10.452791Z","iopub.execute_input":"2024-01-11T10:19:10.453175Z","iopub.status.idle":"2024-01-11T10:19:10.462524Z","shell.execute_reply.started":"2024-01-11T10:19:10.453146Z","shell.execute_reply":"2024-01-11T10:19:10.461412Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"torch.Size([50, 10])"},"metadata":{}}]},{"cell_type":"markdown","source":"### nn.ModuleList","metadata":{}},{"cell_type":"markdown","source":"`nn.ModuleList` does this for us.","metadata":{}},{"cell_type":"code","source":"class SequentialModel(nn.Module):\n    def __init__(self, layer_list):\n        super().__init__()\n        self.layer_list = nn.ModuleList(layer_list)\n        \n    def forward(self, input_data):\n        for layer in self.layer_list:\n            input_data = layer(input_data)\n        return input_data","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:37:31.176040Z","iopub.execute_input":"2024-01-11T16:37:31.177411Z","iopub.status.idle":"2024-01-11T16:37:31.187899Z","shell.execute_reply.started":"2024-01-11T16:37:31.177351Z","shell.execute_reply":"2024-01-11T16:37:31.186170Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"model = SequentialModel(layers)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:37:33.641835Z","iopub.execute_input":"2024-01-11T16:37:33.642360Z","iopub.status.idle":"2024-01-11T16:37:33.650734Z","shell.execute_reply.started":"2024-01-11T16:37:33.642300Z","shell.execute_reply":"2024-01-11T16:37:33.649498Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"SequentialModel(\n  (layer_list): ModuleList(\n    (0): Linear(in_features=784, out_features=50, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=50, out_features=10, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"fit()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:37:38.567910Z","iopub.execute_input":"2024-01-11T16:37:38.568373Z","iopub.status.idle":"2024-01-11T16:37:40.684829Z","shell.execute_reply.started":"2024-01-11T16:37:38.568325Z","shell.execute_reply":"2024-01-11T16:37:40.683611Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Loss: 0.12, Accuracy: 0.96\nLoss: 0.11, Accuracy: 0.96\nLoss: 0.07, Accuracy: 0.98\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### nn.Sequential","metadata":{}},{"cell_type":"markdown","source":"`nn.Sequential` is a convenient class which does the same as the above:","metadata":{}},{"cell_type":"code","source":"model = nn.Sequential(nn.Linear(num_features, hidden_units), nn.ReLU(), nn.Linear(hidden_units,10))","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:37:53.089715Z","iopub.execute_input":"2024-01-11T16:37:53.090130Z","iopub.status.idle":"2024-01-11T16:37:53.096945Z","shell.execute_reply.started":"2024-01-11T16:37:53.090098Z","shell.execute_reply":"2024-01-11T16:37:53.095818Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"fit()\ncross_entropy_loss_func(model(mini_batch_data), mini_batch_labels), accuracy(model(mini_batch_data), mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:38:05.378068Z","iopub.execute_input":"2024-01-11T16:38:05.378520Z","iopub.status.idle":"2024-01-11T16:38:07.245508Z","shell.execute_reply.started":"2024-01-11T16:38:05.378482Z","shell.execute_reply":"2024-01-11T16:38:07.244265Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Loss: 0.15, Accuracy: 0.96\nLoss: 0.11, Accuracy: 0.96\nLoss: 0.09, Accuracy: 0.94\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"(tensor(0.02, grad_fn=<NllLossBackward0>), tensor(1.))"},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:38:14.518552Z","iopub.execute_input":"2024-01-11T16:38:14.518997Z","iopub.status.idle":"2024-01-11T16:38:14.527783Z","shell.execute_reply.started":"2024-01-11T16:38:14.518960Z","shell.execute_reply":"2024-01-11T16:38:14.526602Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Linear(in_features=784, out_features=50, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=50, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"### optim","metadata":{}},{"cell_type":"code","source":"class Optimizer:\n    def __init__(self, params, learning_rate=0.5):\n        self.params = list(params)\n        self.learning_rate = learning_rate\n    \n    def step(self):\n        with torch.no_grad():\n            for param in self.params:\n                param -= param.grad * self.learning_rate\n    \n    def zero_grad(self):\n        for param in self.params:\n            param.grad.data.zero_()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:38:32.648440Z","iopub.execute_input":"2024-01-11T16:38:32.648863Z","iopub.status.idle":"2024-01-11T16:38:32.656750Z","shell.execute_reply.started":"2024-01-11T16:38:32.648832Z","shell.execute_reply":"2024-01-11T16:38:32.655396Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"model = nn.Sequential(nn.Linear(num_features, hidden_units), nn.ReLU(), nn.Linear(hidden_units,10))","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:38:35.073216Z","iopub.execute_input":"2024-01-11T16:38:35.073673Z","iopub.status.idle":"2024-01-11T16:38:35.081031Z","shell.execute_reply.started":"2024-01-11T16:38:35.073641Z","shell.execute_reply":"2024-01-11T16:38:35.080116Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"opt = Optimizer(model.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:38:38.657418Z","iopub.execute_input":"2024-01-11T16:38:38.658205Z","iopub.status.idle":"2024-01-11T16:38:38.663521Z","shell.execute_reply.started":"2024-01-11T16:38:38.658165Z","shell.execute_reply":"2024-01-11T16:38:38.662366Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# Loop through epochs\nfor epoch in range(num_epochs):\n    # Loop through mini-batches\n    for i in range(0, num_samples, batch_size):\n        # Create a slice for the current mini-batch\n        current_slice = slice(i, min(num_samples, i + batch_size))\n        \n        # Extract the mini-batch data and labels\n        mini_batch_data, mini_batch_labels = x_train[current_slice], y_train[current_slice]\n        \n        # Make predictions using the model\n        predictions = model(torch.Tensor(mini_batch_data))\n        \n        # Calculate the loss using the loss function\n        loss_value = cross_entropy_loss_func(predictions, mini_batch_labels)\n        \n        # Backpropagation\n        loss_value.backward()\n        \n        # Update model parameters using gradient descent\n        opt.step()\n        opt.zero_grad()\n    \n    # Report metrics for the last mini-batch in the epoch\n    report_metrics(loss_value.item(), predictions, mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:39:09.791505Z","iopub.execute_input":"2024-01-11T16:39:09.791948Z","iopub.status.idle":"2024-01-11T16:39:11.618546Z","shell.execute_reply.started":"2024-01-11T16:39:09.791918Z","shell.execute_reply":"2024-01-11T16:39:11.617363Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Loss: 0.18, Accuracy: 0.94\nLoss: 0.13, Accuracy: 0.96\nLoss: 0.10, Accuracy: 0.98\n","output_type":"stream"}]},{"cell_type":"markdown","source":"PyTorch already provides this exact functionality in `optim.SGD` (it also handles stuff like momentum, which we'll look at later)","metadata":{}},{"cell_type":"code","source":"from torch import optim","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:39:20.028134Z","iopub.execute_input":"2024-01-11T16:39:20.028646Z","iopub.status.idle":"2024-01-11T16:39:20.034471Z","shell.execute_reply.started":"2024-01-11T16:39:20.028592Z","shell.execute_reply":"2024-01-11T16:39:20.033161Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    model = nn.Sequential(nn.Linear(num_features, hidden_units), nn.ReLU(), nn.Linear(hidden_units,10))\n    return model, optim.SGD(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:39:34.507886Z","iopub.execute_input":"2024-01-11T16:39:34.508374Z","iopub.status.idle":"2024-01-11T16:39:34.514688Z","shell.execute_reply.started":"2024-01-11T16:39:34.508324Z","shell.execute_reply":"2024-01-11T16:39:34.513403Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"model,opt = get_model()\ncross_entropy_loss_func(model(mini_batch_data), mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:39:41.672961Z","iopub.execute_input":"2024-01-11T16:39:41.673397Z","iopub.status.idle":"2024-01-11T16:39:41.684320Z","shell.execute_reply.started":"2024-01-11T16:39:41.673364Z","shell.execute_reply":"2024-01-11T16:39:41.683136Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"tensor(2.33, grad_fn=<NllLossBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"# Loop through epochs\nfor epoch in range(num_epochs):\n    # Loop through mini-batches\n    for i in range(0, num_samples, batch_size):\n        # Create a slice for the current mini-batch\n        current_slice = slice(i, min(num_samples, i + batch_size))\n        \n        # Extract the mini-batch data and labels\n        mini_batch_data, mini_batch_labels = x_train[current_slice], y_train[current_slice]\n        \n        # Make predictions using the model\n        predictions = model(torch.Tensor(mini_batch_data))\n        \n        # Calculate the loss using the loss function\n        loss_value = cross_entropy_loss_func(predictions, mini_batch_labels)\n        \n        # Backpropagation\n        loss_value.backward()\n        \n        # Update model parameters using gradient descent\n        opt.step()\n        opt.zero_grad()\n    \n    # Report metrics for the last mini-batch in the epoch\n    report_metrics(loss_value.item(), predictions, mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:39:50.479647Z","iopub.execute_input":"2024-01-11T16:39:50.480075Z","iopub.status.idle":"2024-01-11T16:39:52.400445Z","shell.execute_reply.started":"2024-01-11T16:39:50.480044Z","shell.execute_reply":"2024-01-11T16:39:52.399224Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Loss: 0.12, Accuracy: 0.98\nLoss: 0.09, Accuracy: 0.98\nLoss: 0.07, Accuracy: 0.98\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Dataset and DataLoader","metadata":{}},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"markdown","source":"It's clunky to iterate through minibatches of x and y values separately:\n\n```python\n    xb = x_train[s]\n    yb = y_train[s]\n```\n\nInstead, let's do these two steps together, by introducing a `Dataset` class:\n\n```python\n    xb,yb = train_ds[s]\n```","metadata":{}},{"cell_type":"code","source":"#|export\nclass Dataset:\n    def __init__(self, input_data, target_data):\n        self.input_data = input_data\n        self.target_data = target_data\n    \n    def __len__(self):\n        return len(self.input_data)\n    \n    def __getitem__(self, index):\n        return self.input_data[index], self.target_data[index]","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:39:59.866416Z","iopub.execute_input":"2024-01-11T16:39:59.866882Z","iopub.status.idle":"2024-01-11T16:39:59.874145Z","shell.execute_reply.started":"2024-01-11T16:39:59.866847Z","shell.execute_reply":"2024-01-11T16:39:59.872726Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"training_dataset, validation_dataset = Dataset(input_data=x_train, target_data=y_train), Dataset(input_data=x_valid, target_data=y_valid)\nassert len(training_dataset) == len(x_train)\nassert len(validation_dataset) == len(x_valid)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:40:05.187025Z","iopub.execute_input":"2024-01-11T16:40:05.187487Z","iopub.status.idle":"2024-01-11T16:40:05.193825Z","shell.execute_reply.started":"2024-01-11T16:40:05.187450Z","shell.execute_reply":"2024-01-11T16:40:05.192203Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"x_train_batch, y_train_batch = training_dataset[0:5]\nassert x_train_batch.shape == (5, 28*28)\nassert y_train_batch.shape == (5,)\nx_train_batch, y_train_batch","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:40:05.731178Z","iopub.execute_input":"2024-01-11T16:40:05.731971Z","iopub.status.idle":"2024-01-11T16:40:05.741595Z","shell.execute_reply.started":"2024-01-11T16:40:05.731930Z","shell.execute_reply":"2024-01-11T16:40:05.740420Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n tensor([5, 0, 4, 1, 9]))"},"metadata":{}}]},{"cell_type":"code","source":"model,opt = get_model()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:40:06.825531Z","iopub.execute_input":"2024-01-11T16:40:06.826377Z","iopub.status.idle":"2024-01-11T16:40:06.833227Z","shell.execute_reply.started":"2024-01-11T16:40:06.826308Z","shell.execute_reply":"2024-01-11T16:40:06.831991Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# Loop through epochs\nfor epoch in range(num_epochs):\n    # Loop through mini-batches\n    for i in range(0, num_samples, batch_size):\n        # Extract the mini-batch data and labels\n        mini_batch_data, mini_batch_labels = training_dataset[i:min(num_samples, i + batch_size)]\n        \n        # Make predictions using the model\n        predictions = model(torch.Tensor(mini_batch_data))\n        \n        # Calculate the loss using the loss function\n        loss_value = cross_entropy_loss_func(predictions, mini_batch_labels)\n        \n        # Backpropagation\n        loss_value.backward()\n        \n        # Update model parameters using gradient descent\n        opt.step()\n        opt.zero_grad()\n    \n    # Report metrics for the last mini-batch in the epoch\n    report_metrics(loss_value.item(), predictions, mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:40:07.648096Z","iopub.execute_input":"2024-01-11T16:40:07.648603Z","iopub.status.idle":"2024-01-11T16:40:09.553026Z","shell.execute_reply.started":"2024-01-11T16:40:07.648561Z","shell.execute_reply":"2024-01-11T16:40:09.552155Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Loss: 0.17, Accuracy: 0.96\nLoss: 0.11, Accuracy: 0.94\nLoss: 0.09, Accuracy: 0.96\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### DataLoader","metadata":{}},{"cell_type":"markdown","source":"Previously, our loop iterated over batches (xb, yb) like this:\n\n```python\nfor i in range(0, n, bs):\n    xb,yb = train_ds[i:min(n,i+bs)]\n    ...\n```\n\nLet's make our loop much cleaner, using a data loader:\n\n```python\nfor xb,yb in train_dl:\n    ...\n```","metadata":{}},{"cell_type":"code","source":"class DataLoader:\n    def __init__(self, dataset, batch_size):\n        self.dataset = dataset\n        self.batch_size = batch_size\n    \n    def __iter__(self):\n        for i in range(0, len(self.dataset), self.batch_size):\n            yield self.dataset[i:i+self.batch_size]","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:41:01.100684Z","iopub.execute_input":"2024-01-11T16:41:01.101135Z","iopub.status.idle":"2024-01-11T16:41:01.109448Z","shell.execute_reply.started":"2024-01-11T16:41:01.101104Z","shell.execute_reply":"2024-01-11T16:41:01.107815Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(training_dataset, batch_size)\nvalid_dataloader = DataLoader(validation_dataset, batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:41:07.036606Z","iopub.execute_input":"2024-01-11T16:41:07.037750Z","iopub.status.idle":"2024-01-11T16:41:07.043062Z","shell.execute_reply.started":"2024-01-11T16:41:07.037706Z","shell.execute_reply":"2024-01-11T16:41:07.041682Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"mini_batch_data, mini_batch_labels = next(iter(valid_dataloader))\nmini_batch_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:41:15.537252Z","iopub.execute_input":"2024-01-11T16:41:15.537764Z","iopub.status.idle":"2024-01-11T16:41:15.546241Z","shell.execute_reply.started":"2024-01-11T16:41:15.537722Z","shell.execute_reply":"2024-01-11T16:41:15.545111Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"torch.Size([50, 784])"},"metadata":{}}]},{"cell_type":"code","source":"mini_batch_labels","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:41:17.175911Z","iopub.execute_input":"2024-01-11T16:41:17.177092Z","iopub.status.idle":"2024-01-11T16:41:17.185214Z","shell.execute_reply.started":"2024-01-11T16:41:17.177044Z","shell.execute_reply":"2024-01-11T16:41:17.183984Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"tensor([3, 8, 6, 9, 6, 4, 5, 3, 8, 4, 5, 2, 3, 8, 4, 8, 1, 5, 0, 5, 9, 7, 4, 1, 0, 3, 0, 6, 2, 9, 9, 4, 1, 3, 6, 8, 0, 7, 7, 6, 8, 9, 0, 3,\n        8, 3, 7, 7, 8, 4])"},"metadata":{}}]},{"cell_type":"code","source":"plt.imshow(mini_batch_data[0].view(28,28))\nmini_batch_labels[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:41:19.767711Z","iopub.execute_input":"2024-01-11T16:41:19.768813Z","iopub.status.idle":"2024-01-11T16:41:20.102766Z","shell.execute_reply.started":"2024-01-11T16:41:19.768758Z","shell.execute_reply":"2024-01-11T16:41:20.101529Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"tensor(3)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"model,opt = get_model()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:41:20.801956Z","iopub.execute_input":"2024-01-11T16:41:20.803141Z","iopub.status.idle":"2024-01-11T16:41:20.809552Z","shell.execute_reply.started":"2024-01-11T16:41:20.803091Z","shell.execute_reply":"2024-01-11T16:41:20.808241Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"def fit():\n    # Loop through epochs\n    for epoch in range(num_epochs):\n        # Loop through mini-batches\n        for mini_batch_data, mini_batch_labels in train_dataloader:\n            # Make predictions using the model\n            predictions = model(torch.Tensor(mini_batch_data))\n\n            # Calculate the loss using the loss function\n            loss_value = cross_entropy_loss_func(predictions, mini_batch_labels)\n\n            # Backpropagation\n            loss_value.backward()\n\n            # Update model parameters using gradient descent\n            opt.step()\n            opt.zero_grad()\n\n        # Report metrics for the last mini-batch in the epoch\n        report_metrics(loss_value.item(), predictions, mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:41:48.715666Z","iopub.execute_input":"2024-01-11T16:41:48.716097Z","iopub.status.idle":"2024-01-11T16:41:48.725205Z","shell.execute_reply.started":"2024-01-11T16:41:48.716067Z","shell.execute_reply":"2024-01-11T16:41:48.723472Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"fit()\ncross_entropy_loss_func(model(mini_batch_data), mini_batch_labels), accuracy(model(mini_batch_data), mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:41:54.961483Z","iopub.execute_input":"2024-01-11T16:41:54.961958Z","iopub.status.idle":"2024-01-11T16:41:56.856559Z","shell.execute_reply.started":"2024-01-11T16:41:54.961922Z","shell.execute_reply":"2024-01-11T16:41:56.855415Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Loss: 0.11, Accuracy: 0.98\nLoss: 0.09, Accuracy: 0.98\nLoss: 0.06, Accuracy: 1.00\n","output_type":"stream"},{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"(tensor(0.03, grad_fn=<NllLossBackward0>), tensor(1.))"},"metadata":{}}]},{"cell_type":"markdown","source":"### Random sampling","metadata":{}},{"cell_type":"markdown","source":"We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized.","metadata":{}},{"cell_type":"code","source":"import random","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:42:08.785525Z","iopub.execute_input":"2024-01-11T16:42:08.785982Z","iopub.status.idle":"2024-01-11T16:42:08.791593Z","shell.execute_reply.started":"2024-01-11T16:42:08.785944Z","shell.execute_reply":"2024-01-11T16:42:08.790417Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"class Sampler:\n    def __init__(self, dataset, shuffle=False):\n        self.num_samples, self.shuffle = len(dataset), shuffle\n    \n    def __iter__(self):\n        sample_indices = list(range(self.num_samples))\n        if self.shuffle:\n            random.shuffle(sample_indices)\n        return iter(sample_indices)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:42:09.916568Z","iopub.execute_input":"2024-01-11T16:42:09.917022Z","iopub.status.idle":"2024-01-11T16:42:09.924893Z","shell.execute_reply.started":"2024-01-11T16:42:09.916988Z","shell.execute_reply":"2024-01-11T16:42:09.923539Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"from itertools import islice","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:42:33.262754Z","iopub.execute_input":"2024-01-11T16:42:33.263199Z","iopub.status.idle":"2024-01-11T16:42:33.268625Z","shell.execute_reply.started":"2024-01-11T16:42:33.263169Z","shell.execute_reply":"2024-01-11T16:42:33.267440Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"ss = Sampler(training_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:42:33.695975Z","iopub.execute_input":"2024-01-11T16:42:33.696432Z","iopub.status.idle":"2024-01-11T16:42:33.702032Z","shell.execute_reply.started":"2024-01-11T16:42:33.696398Z","shell.execute_reply":"2024-01-11T16:42:33.700812Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"it = iter(ss)\nfor o in range(5):\n    print(next(it))","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:42:43.242476Z","iopub.execute_input":"2024-01-11T16:42:43.242911Z","iopub.status.idle":"2024-01-11T16:42:43.250941Z","shell.execute_reply.started":"2024-01-11T16:42:43.242879Z","shell.execute_reply":"2024-01-11T16:42:43.249677Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"0\n1\n2\n3\n4\n","output_type":"stream"}]},{"cell_type":"code","source":"list(islice(ss, 5))","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:42:46.806356Z","iopub.execute_input":"2024-01-11T16:42:46.806814Z","iopub.status.idle":"2024-01-11T16:42:46.817483Z","shell.execute_reply.started":"2024-01-11T16:42:46.806777Z","shell.execute_reply":"2024-01-11T16:42:46.816208Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"[0, 1, 2, 3, 4]"},"metadata":{}}]},{"cell_type":"code","source":"ss = Sampler(training_dataset, shuffle=True)\nlist(islice(ss, 5))","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:42:47.083411Z","iopub.execute_input":"2024-01-11T16:42:47.083849Z","iopub.status.idle":"2024-01-11T16:42:47.147745Z","shell.execute_reply.started":"2024-01-11T16:42:47.083816Z","shell.execute_reply":"2024-01-11T16:42:47.146304Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"[553, 38875, 43564, 12413, 4468]"},"metadata":{}}]},{"cell_type":"code","source":"import fastcore.all as fc","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:42:48.330653Z","iopub.execute_input":"2024-01-11T16:42:48.331113Z","iopub.status.idle":"2024-01-11T16:42:48.366579Z","shell.execute_reply.started":"2024-01-11T16:42:48.331076Z","shell.execute_reply":"2024-01-11T16:42:48.365397Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"class BatchSampler:\n    def __init__(self, sampler, batch_size, drop_last=False):\n        self.sampler = sampler\n        self.batch_size = batch_size\n        self.drop_last = drop_last\n    \n    def __iter__(self):\n        for batch in fc.chunked(iter(self.sampler), self.batch_size, drop_last=self.drop_last):\n            yield batch","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:43:11.403075Z","iopub.execute_input":"2024-01-11T16:43:11.403688Z","iopub.status.idle":"2024-01-11T16:43:11.411620Z","shell.execute_reply.started":"2024-01-11T16:43:11.403651Z","shell.execute_reply":"2024-01-11T16:43:11.410162Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"batchs = BatchSampler(ss, 4)\nlist(islice(batchs, 5))","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:43:24.072837Z","iopub.execute_input":"2024-01-11T16:43:24.073271Z","iopub.status.idle":"2024-01-11T16:43:24.139307Z","shell.execute_reply.started":"2024-01-11T16:43:24.073236Z","shell.execute_reply":"2024-01-11T16:43:24.138098Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"[[23681, 86, 31686, 34587],\n [41260, 46576, 41667, 15860],\n [18159, 46216, 45492, 46269],\n [19000, 40491, 36189, 49914],\n [34562, 13726, 16760, 25376]]"},"metadata":{}}]},{"cell_type":"code","source":"def collate(batch):\n    inputs, targets = zip(*batch)\n    return torch.stack(inputs), torch.stack(targets)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:43:40.126946Z","iopub.execute_input":"2024-01-11T16:43:40.127471Z","iopub.status.idle":"2024-01-11T16:43:40.132900Z","shell.execute_reply.started":"2024-01-11T16:43:40.127432Z","shell.execute_reply":"2024-01-11T16:43:40.131751Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"class DataLoader:\n    def __init__(self, dataset, batches, collate_fn=collate):\n        fc.store_attr()\n    \n    def __iter__(self):\n         yield from (self.collate_fn(self.dataset[i] for i in batch) for batch in self.batches)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:43:47.634421Z","iopub.execute_input":"2024-01-11T16:43:47.634845Z","iopub.status.idle":"2024-01-11T16:43:47.642300Z","shell.execute_reply.started":"2024-01-11T16:43:47.634814Z","shell.execute_reply":"2024-01-11T16:43:47.641116Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"train_sampler = BatchSampler(Sampler(training_dataset,   shuffle=True ), batch_size)\nvalid_sampler = BatchSampler(Sampler(validation_dataset, shuffle=False), batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:44:24.811323Z","iopub.execute_input":"2024-01-11T16:44:24.811792Z","iopub.status.idle":"2024-01-11T16:44:24.818429Z","shell.execute_reply.started":"2024-01-11T16:44:24.811760Z","shell.execute_reply":"2024-01-11T16:44:24.817075Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(training_dataset, batches=train_sampler)\nvalid_dataloader = DataLoader(validation_dataset, batches=valid_sampler)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:44:36.982455Z","iopub.execute_input":"2024-01-11T16:44:36.982886Z","iopub.status.idle":"2024-01-11T16:44:36.988596Z","shell.execute_reply.started":"2024-01-11T16:44:36.982856Z","shell.execute_reply":"2024-01-11T16:44:36.987427Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"mini_batch_data, mini_batch_labels = next(iter(valid_dataloader))\nplt.imshow(mini_batch_data[0].view(28,28))\nmini_batch_labels[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:44:40.646641Z","iopub.execute_input":"2024-01-11T16:44:40.647078Z","iopub.status.idle":"2024-01-11T16:44:40.942935Z","shell.execute_reply.started":"2024-01-11T16:44:40.647046Z","shell.execute_reply":"2024-01-11T16:44:40.941807Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"tensor(3)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"mini_batch_data.shape, mini_batch_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:44:41.670735Z","iopub.execute_input":"2024-01-11T16:44:41.671164Z","iopub.status.idle":"2024-01-11T16:44:41.679087Z","shell.execute_reply.started":"2024-01-11T16:44:41.671128Z","shell.execute_reply":"2024-01-11T16:44:41.677912Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"(torch.Size([50, 784]), torch.Size([50]))"},"metadata":{}}]},{"cell_type":"code","source":"model,opt = get_model()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:44:44.657182Z","iopub.execute_input":"2024-01-11T16:44:44.657645Z","iopub.status.idle":"2024-01-11T16:44:44.664493Z","shell.execute_reply.started":"2024-01-11T16:44:44.657611Z","shell.execute_reply":"2024-01-11T16:44:44.663078Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"fit()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:45:14.438400Z","iopub.execute_input":"2024-01-11T16:45:14.438840Z","iopub.status.idle":"2024-01-11T16:45:17.801642Z","shell.execute_reply.started":"2024-01-11T16:45:14.438802Z","shell.execute_reply":"2024-01-11T16:45:17.800431Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"Loss: 0.40, Accuracy: 0.86\nLoss: 0.19, Accuracy: 0.96\nLoss: 0.24, Accuracy: 0.96\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Multiprocessing DataLoader","metadata":{}},{"cell_type":"code","source":"import torch.multiprocessing as mp","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:45:21.402513Z","iopub.execute_input":"2024-01-11T16:45:21.402974Z","iopub.status.idle":"2024-01-11T16:45:21.408658Z","shell.execute_reply.started":"2024-01-11T16:45:21.402936Z","shell.execute_reply":"2024-01-11T16:45:21.407620Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"training_dataset[[3,6,8,1]]","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:45:21.822629Z","iopub.execute_input":"2024-01-11T16:45:21.823503Z","iopub.status.idle":"2024-01-11T16:45:21.832393Z","shell.execute_reply.started":"2024-01-11T16:45:21.823463Z","shell.execute_reply":"2024-01-11T16:45:21.831224Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n tensor([1, 1, 1, 0]))"},"metadata":{}}]},{"cell_type":"code","source":"training_dataset.__getitem__([3,6,8,1])","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:45:22.552435Z","iopub.execute_input":"2024-01-11T16:45:22.552908Z","iopub.status.idle":"2024-01-11T16:45:22.563901Z","shell.execute_reply.started":"2024-01-11T16:45:22.552869Z","shell.execute_reply":"2024-01-11T16:45:22.562566Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n tensor([1, 1, 1, 0]))"},"metadata":{}}]},{"cell_type":"code","source":"for o in map(training_dataset.__getitem__, ([3,6],[8,1])):\n    print(o)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:45:25.123262Z","iopub.execute_input":"2024-01-11T16:45:25.123731Z","iopub.status.idle":"2024-01-11T16:45:25.134043Z","shell.execute_reply.started":"2024-01-11T16:45:25.123693Z","shell.execute_reply":"2024-01-11T16:45:25.132542Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n","output_type":"stream"}]},{"cell_type":"code","source":"class DataLoader:\n    def __init__(self, dataset, batches, num_workers=1, collate_function=collate):\n        fc.store_attr()\n    \n    def __iter__(self):\n        with mp.Pool(self.num_workers) as executor:\n            yield from executor.map(self.dataset.__getitem__, iter(self.batches))","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:45:25.635998Z","iopub.execute_input":"2024-01-11T16:45:25.636712Z","iopub.status.idle":"2024-01-11T16:45:25.644037Z","shell.execute_reply.started":"2024-01-11T16:45:25.636676Z","shell.execute_reply":"2024-01-11T16:45:25.642195Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(training_dataset, batches=train_sampler, num_workers=8)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:45:57.550008Z","iopub.execute_input":"2024-01-11T16:45:57.550518Z","iopub.status.idle":"2024-01-11T16:45:57.555930Z","shell.execute_reply.started":"2024-01-11T16:45:57.550476Z","shell.execute_reply":"2024-01-11T16:45:57.554683Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"it = iter(train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:46:03.718126Z","iopub.execute_input":"2024-01-11T16:46:03.718855Z","iopub.status.idle":"2024-01-11T16:46:03.723925Z","shell.execute_reply.started":"2024-01-11T16:46:03.718813Z","shell.execute_reply":"2024-01-11T16:46:03.722873Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# mini_batch_data, mini_batch_labels = next(it)\n# mini_batch_data.shape, mini_batch_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:46:10.881609Z","iopub.execute_input":"2024-01-11T16:46:10.882307Z","iopub.status.idle":"2024-01-11T16:46:10.886802Z","shell.execute_reply.started":"2024-01-11T16:46:10.882267Z","shell.execute_reply":"2024-01-11T16:46:10.885526Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"### PyTorch DataLoader","metadata":{}},{"cell_type":"code","source":"#|export\nfrom torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:46:16.495306Z","iopub.execute_input":"2024-01-11T16:46:16.495759Z","iopub.status.idle":"2024-01-11T16:46:16.501515Z","shell.execute_reply.started":"2024-01-11T16:46:16.495723Z","shell.execute_reply":"2024-01-11T16:46:16.499999Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"DataLoader?","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:49:43.687981Z","iopub.execute_input":"2024-01-11T16:49:43.688435Z","iopub.status.idle":"2024-01-11T16:49:43.704949Z","shell.execute_reply.started":"2024-01-11T16:49:43.688402Z","shell.execute_reply":"2024-01-11T16:49:43.703425Z"},"trusted":true},"execution_count":111,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mInit signature:\u001b[0m\n\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mT_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mbatch_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mnum_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mcollate_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mworker_init_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmultiprocessing_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mprefetch_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mpersistent_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mpin_memory_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m     \nData loader. Combines a dataset and a sampler, and provides an iterable over\nthe given dataset.\n\nThe :class:`~torch.utils.data.DataLoader` supports both map-style and\niterable-style datasets with single- or multi-process loading, customizing\nloading order and optional automatic batching (collation) and memory pinning.\n\nSee :py:mod:`torch.utils.data` documentation page for more details.\n\nArgs:\n    dataset (Dataset): dataset from which to load the data.\n    batch_size (int, optional): how many samples per batch to load\n        (default: ``1``).\n    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n        at every epoch (default: ``False``).\n    sampler (Sampler or Iterable, optional): defines the strategy to draw\n        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n        implemented. If specified, :attr:`shuffle` must not be specified.\n    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n        returns a batch of indices at a time. Mutually exclusive with\n        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n        and :attr:`drop_last`.\n    num_workers (int, optional): how many subprocesses to use for data\n        loading. ``0`` means that the data will be loaded in the main process.\n        (default: ``0``)\n    collate_fn (Callable, optional): merges a list of samples to form a\n        mini-batch of Tensor(s).  Used when using batched loading from a\n        map-style dataset.\n    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n        into device/CUDA pinned memory before returning them.  If your data elements\n        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n        see the example below.\n    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n        if the dataset size is not divisible by the batch size. If ``False`` and\n        the size of dataset is not divisible by the batch size, then the last batch\n        will be smaller. (default: ``False``)\n    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n        from workers. Should always be non-negative. (default: ``0``)\n    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n        input, after seeding and before data loading. (default: ``None``)\n    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n        by RandomSampler to generate random indexes and multiprocessing to generate\n        `base_seed` for workers. (default: ``None``)\n    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n        in advance by each worker. ``2`` means there will be a total of\n        2 * num_workers batches prefetched across all workers. (default value depends\n        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n        Otherwise if value of num_workers>0 default is ``2``).\n    persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n        the worker processes after a dataset has been consumed once. This allows to\n        maintain the workers `Dataset` instances alive. (default: ``False``)\n    pin_memory_device (str, optional): the data loader will copy Tensors\n        into device pinned memory before returning them if pin_memory is set to true.\n\n\n.. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n             cannot be an unpicklable object, e.g., a lambda function. See\n             :ref:`multiprocessing-best-practices` on more details related\n             to multiprocessing in PyTorch.\n\n.. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n             configurations. This represents the best guess PyTorch can make because PyTorch\n             trusts user :attr:`dataset` code in correctly handling multi-process\n             loading to avoid duplicate data.\n\n             However, if sharding results in multiple workers having incomplete last batches,\n             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n             be broken into multiple ones and (2) more than one batch worth of samples can be\n             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n             cases in general.\n\n             See `Dataset Types`_ for more details on these two types of datasets and how\n             :class:`~torch.utils.data.IterableDataset` interacts with\n             `Multi-process data loading`_.\n\n.. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n             :ref:`data-loading-randomness` notes for random seed related questions.\n\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\n\u001b[0;31mType:\u001b[0m           type\n\u001b[0;31mSubclasses:\u001b[0m     "},"metadata":{}}]},{"cell_type":"code","source":"train_sampler = BatchSampler(RandomSampler(training_dataset),       batch_size, drop_last=False)\nvalid_sampler = BatchSampler(SequentialSampler(validation_dataset), batch_size, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:46:32.484519Z","iopub.execute_input":"2024-01-11T16:46:32.485004Z","iopub.status.idle":"2024-01-11T16:46:32.491109Z","shell.execute_reply.started":"2024-01-11T16:46:32.484967Z","shell.execute_reply":"2024-01-11T16:46:32.489690Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(training_dataset,   batch_sampler=train_sampler, collate_fn=collate)\nvalid_dataloader = DataLoader(validation_dataset, batch_sampler=valid_sampler, collate_fn=collate)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:46:50.799354Z","iopub.execute_input":"2024-01-11T16:46:50.800239Z","iopub.status.idle":"2024-01-11T16:46:50.806409Z","shell.execute_reply.started":"2024-01-11T16:46:50.800191Z","shell.execute_reply":"2024-01-11T16:46:50.805163Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"model,opt = get_model()\nfit()\ncross_entropy_loss_func(model(mini_batch_data), mini_batch_labels), accuracy(model(mini_batch_data), mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:46:54.178799Z","iopub.execute_input":"2024-01-11T16:46:54.179671Z","iopub.status.idle":"2024-01-11T16:46:57.571512Z","shell.execute_reply.started":"2024-01-11T16:46:54.179623Z","shell.execute_reply":"2024-01-11T16:46:57.570391Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"Loss: 0.10, Accuracy: 0.94\nLoss: 0.10, Accuracy: 0.96\nLoss: 0.27, Accuracy: 0.98\n","output_type":"stream"},{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"(tensor(0.05, grad_fn=<NllLossBackward0>), tensor(0.98))"},"metadata":{}}]},{"cell_type":"markdown","source":"PyTorch can auto-generate the BatchSampler for us:","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(training_dataset, batch_size, sampler=RandomSampler(training_dataset), collate_fn=collate)\nvalid_dataloader = DataLoader(validation_dataset, batch_size, sampler=SequentialSampler(validation_dataset), collate_fn=collate)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:47:23.071407Z","iopub.execute_input":"2024-01-11T16:47:23.072391Z","iopub.status.idle":"2024-01-11T16:47:23.078121Z","shell.execute_reply.started":"2024-01-11T16:47:23.072315Z","shell.execute_reply":"2024-01-11T16:47:23.076846Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":"PyTorch can also generate the Sequential/RandomSamplers too:","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(training_dataset, batch_size, shuffle=True, drop_last=True, num_workers=2)\nvalid_dataloader = DataLoader(validation_dataset, batch_size, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:50:11.537570Z","iopub.execute_input":"2024-01-11T16:50:11.538802Z","iopub.status.idle":"2024-01-11T16:50:11.544512Z","shell.execute_reply.started":"2024-01-11T16:50:11.538755Z","shell.execute_reply":"2024-01-11T16:50:11.543283Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"model,opt = get_model()\nfit()\n\ncross_entropy_loss_func(model(mini_batch_data), mini_batch_labels), accuracy(model(mini_batch_data), mini_batch_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:50:13.794025Z","iopub.execute_input":"2024-01-11T16:50:13.794509Z","iopub.status.idle":"2024-01-11T16:50:23.543871Z","shell.execute_reply.started":"2024-01-11T16:50:13.794466Z","shell.execute_reply":"2024-01-11T16:50:23.542664Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Loss: 0.21, Accuracy: 0.92\nLoss: 0.15, Accuracy: 0.94\nLoss: 0.04, Accuracy: 0.98\n","output_type":"stream"},{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"(tensor(0.01, grad_fn=<NllLossBackward0>), tensor(1.))"},"metadata":{}}]},{"cell_type":"markdown","source":"Our dataset actually already knows how to sample a batch of indices all at once:","metadata":{}},{"cell_type":"code","source":"training_dataset[[4,6,7]]","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:50:23.545993Z","iopub.execute_input":"2024-01-11T16:50:23.547204Z","iopub.status.idle":"2024-01-11T16:50:23.555264Z","shell.execute_reply.started":"2024-01-11T16:50:23.547165Z","shell.execute_reply":"2024-01-11T16:50:23.554462Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n tensor([9, 1, 3]))"},"metadata":{}}]},{"cell_type":"markdown","source":"...that means that we can actually skip the batch_sampler and collate_fn entirely:","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(training_dataset, sampler=train_sampler)\nvalid_dataloader = DataLoader(validation_dataset, sampler=valid_sampler)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:50:37.540650Z","iopub.execute_input":"2024-01-11T16:50:37.541916Z","iopub.status.idle":"2024-01-11T16:50:37.547592Z","shell.execute_reply.started":"2024-01-11T16:50:37.541873Z","shell.execute_reply":"2024-01-11T16:50:37.546409Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"mini_batch_data, mini_batch_labels = next(iter(train_dataloader))\nmini_batch_data.shape, mini_batch_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:50:50.523071Z","iopub.execute_input":"2024-01-11T16:50:50.523588Z","iopub.status.idle":"2024-01-11T16:50:50.539088Z","shell.execute_reply.started":"2024-01-11T16:50:50.523546Z","shell.execute_reply":"2024-01-11T16:50:50.537785Z"},"trusted":true},"execution_count":116,"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"(torch.Size([1, 50, 784]), torch.Size([1, 50]))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Validation","metadata":{}},{"cell_type":"markdown","source":"You **always** should also have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/), in order to identify if you are overfitting.\n\nWe will calculate and print the validation loss at the end of each epoch.\n\n(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)","metadata":{}},{"cell_type":"code","source":"#|export\ndef fit(num_epochs, model, loss_function, optimizer, train_loader, validation_loader):\n    \"\"\"\n    Trains a neural network model on a given dataset for a specified number of epochs.\n    \n    Parameters:\n    ----------\n    num_epochs : int\n        Number of epochs to train the model for.\n    model : torch.nn.Module\n        Neural network model to be trained.\n    loss_function : Callable\n        Function that calculates the loss between the model's predictions and the true labels.\n    optimizer : torch.optim.Optimizer\n        Optimization algorithm to use for updating the model's parameters.\n    train_loader : torch.utils.data.DataLoader\n        Iterator that loads the training data in mini-batches.\n    validation_loader : torch.utils.data.DataLoader\n        Iterator that loads the validation data in mini-batches.\n    \n    Returns:\n    -------\n    total_loss : float\n        Total loss accumulated across all mini-batches in the validation set.\n    total_accuracy : float\n        Total accuracy accumulated across all mini-batches in the validation set.\n    \"\"\"\n    # Loop through epochs\n    for epoch in range(num_epochs):\n        # Set the model to training mode\n        model.train()\n        \n        # Loop through mini-batches in training data\n        for batch_data, batch_labels in train_loader:\n            # Make predictions using the model\n            predictions = model(torch.Tensor(batch_data))\n            \n            # Calculate the loss using the loss function\n            loss_value = loss_function(predictions, batch_labels)\n            \n            # Perform backpropagation\n            loss_value.backward()\n            \n            # Update model parameters using gradient descent\n            optimizer.step()\n            optimizer.zero_grad()\n        \n        # Set the model to evaluation mode\n        model.eval()\n        \n        # Initialize variables to store total loss and accuracy\n        total_loss, total_accuracy, batch_count = 0., 0., 0\n        \n        # Loop through mini-batches in validation data\n        for batch_data, batch_labels in validation_loader:\n            # Make predictions using the model\n            predictions = model(torch.Tensor(batch_data))\n            \n            # Calculate the loss using the loss function\n            loss_value = loss_function(predictions, batch_labels)\n            \n            # Add the loss and accuracy to the respective totals\n            total_loss += loss_value.item() * len(batch_data)\n            total_accuracy += accuracy(predictions, batch_labels).item() * len(batch_data)\n            \n            # Increment the batch count\n            batch_count += len(batch_data)\n        \n        # Print the epoch, total loss, and total accuracy\n        print(f\"Epoch {epoch + 1}, Total Loss: {total_loss / batch_count}, Total Accuracy: {total_accuracy / batch_count}\")\n    \n    # Return the total loss and accuracy\n    return total_loss / batch_count, total_accuracy / batch_count","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:52:32.818362Z","iopub.execute_input":"2024-01-11T16:52:32.818851Z","iopub.status.idle":"2024-01-11T16:52:32.831198Z","shell.execute_reply.started":"2024-01-11T16:52:32.818812Z","shell.execute_reply":"2024-01-11T16:52:32.830137Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"\n#|export\ndef get_dataloaders(training_dataset, validation_dataset, batch_size, **kwargs):\n    \"\"\"\n    Creates data loaders for training and validation data.\n    \n    Parameters:\n    -----------\n    training_dataset: torch.utils.data.Dataset\n        The dataset to use for training.\n    validation_dataset: torch.utils.data.Dataset\n        The dataset to use for validation.\n    batch_size: int\n        The batch size to use for both training and validation data loaders.\n    **kwargs: dict\n        Optional keywords arguments to pass to the DataLoader constructor.\n    \n    Returns:\n    --------\n    tuple(DataLoader, DataLoader)\n        A tuple containing two data loaders, one for training and one for validation.\n    \"\"\"\n    train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n    validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size*2, **kwargs)\n    return train_dataloader, validation_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:52:55.579638Z","iopub.execute_input":"2024-01-11T16:52:55.580090Z","iopub.status.idle":"2024-01-11T16:52:55.588355Z","shell.execute_reply.started":"2024-01-11T16:52:55.580056Z","shell.execute_reply":"2024-01-11T16:52:55.586562Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:","metadata":{}},{"cell_type":"code","source":"train_dataloader, valid_dataloader = get_dataloaders(training_dataset, validation_dataset, batch_size)\nmodel,opt = get_model()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:53:14.286898Z","iopub.execute_input":"2024-01-11T16:53:14.287379Z","iopub.status.idle":"2024-01-11T16:53:14.294328Z","shell.execute_reply.started":"2024-01-11T16:53:14.287323Z","shell.execute_reply":"2024-01-11T16:53:14.293277Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"%time loss,acc = fit(5, model, cross_entropy_loss_func, opt, train_dataloader, valid_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T16:53:28.934559Z","iopub.execute_input":"2024-01-11T16:53:28.935949Z","iopub.status.idle":"2024-01-11T16:53:35.385666Z","shell.execute_reply.started":"2024-01-11T16:53:28.935894Z","shell.execute_reply":"2024-01-11T16:53:35.384509Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"Epoch 1, Total Loss: 0.14047490478493274, Total Accuracy: 0.9582000035047531\nEpoch 2, Total Loss: 0.12209551422856749, Total Accuracy: 0.9635000067949295\nEpoch 3, Total Loss: 0.13450034762732685, Total Accuracy: 0.9630000048875809\nEpoch 4, Total Loss: 0.11124097333289683, Total Accuracy: 0.9662000066041947\nEpoch 5, Total Loss: 0.11131250839214772, Total Accuracy: 0.9704000061750412\nCPU times: user 12.8 s, sys: 63.1 ms, total: 12.9 s\nWall time: 6.44 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Export -","metadata":{}},{"cell_type":"code","source":"# import nbdev; nbdev.nbdev_export()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:28:28.879327Z","iopub.execute_input":"2024-01-11T13:28:28.880037Z","iopub.status.idle":"2024-01-11T13:28:28.883550Z","shell.execute_reply.started":"2024-01-11T13:28:28.880001Z","shell.execute_reply":"2024-01-11T13:28:28.882732Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"# !pip install nbdev","metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:28:33.280265Z","iopub.execute_input":"2024-01-11T13:28:33.281043Z","iopub.status.idle":"2024-01-11T13:28:33.285195Z","shell.execute_reply.started":"2024-01-11T13:28:33.281008Z","shell.execute_reply":"2024-01-11T13:28:33.284131Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}