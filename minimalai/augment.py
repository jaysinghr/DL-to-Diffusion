# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/14_minimalai-augment.ipynb.

# %% auto 0
__all__ = ['summary', 'show_image_batch', 'CapturePreds', 'capture_preds', 'random_erasing', 'random_erase', 'RandomErasing',
           'random_copy1', 'random_copy', 'RandomCopy']

# %% ../nbs/14_minimalai-augment.ipynb 3
import torch, random
import fastcore.all as fc

from torch import nn
from torch.nn import init

from .datasets import *
from .conv import *
from .learner import *
from .activations import *
from .init import *
from .sgd import *
from .resnet import *

# %% ../nbs/14_minimalai-augment.ipynb 17
def _flops(x, h, w):
    """
    Calculate the number of floating-point operations (FLOPs) for a given input tensor.

    Args:
    - x (torch.Tensor): Input tensor.
    - h (int): Height of the tensor.
    - w (int): Width of the tensor.

    Returns:
    - int: Number of FLOPs.
    """
    if x.dim() < 3:
        return x.numel()
    if x.dim() == 4:
        return x.numel() * h * w

# Patch the summary method to the Learner class
@fc.patch
def summary(self: Learner):
    """
    Generate a summary of the model including module names, input and output shapes, the number of parameters, and MFLOPs.

    Returns:
    - Markdown or None: If running in a notebook environment, returns a Markdown table of the summary. Otherwise, prints the summary.
    """
    res = '|Module|Input|Output|Num params|MFLOPS|\n|--|--|--|--|--|\n'
    total_params, total_flops = 0, 0

    def _hook_fn(hook, mod, inp, outp):
        nonlocal res, total_params, total_flops
        # Calculate the number of parameters
        num_params = sum(p.numel() for p in mod.parameters())
        total_params += num_params
        # Calculate the number of FLOPs
        *_, h, w = outp.shape
        flops = sum(_flops(p, h, w) for p in mod.parameters()) / 1e6
        total_flops += flops
        # Update the summary table
        res += f'|{type(mod).__name__}|{tuple(inp[0].shape)}|{tuple(outp.shape)}|{num_params}|{flops:.1f}|\n'

    # Apply the hook function to the model
    with Hooks(self.model, _hook_fn) as hooks:
        self.fit(1, learning_rate=1, callbacks=SingleBatchCallback())

    # Print the total number of parameters and MFLOPs
    print(f"Total params: {total_params}; MFLOPS: {total_flops:.1f}")

    # Return the summary as Markdown if running in a notebook environment
    if fc.IN_NOTEBOOK:
        from IPython.display import Markdown
        return Markdown(res)
    else:
        print(res)

# %% ../nbs/14_minimalai-augment.ipynb 34
@fc.patch
@fc.delegates(show_images)
def show_image_batch(self: Learner, max_n=9, callbacks=None, **kwargs):
    """
    Fit the model for one epoch and display a batch of images.

    Args:
    - self (Learner): The learner instance.
    - max_n (int): Maximum number of images to display.
    - callbacks (list or Callback): Additional callbacks to be applied during fitting.

    Other arguments are delegated to the `show_images` function.
    """
    # Fit the model for one epoch with SingleBatchCB and additional callbacks
    self.fit(1, callbacks=[SingleBatchCallback()] + fc.L(callbacks))
    
    # Display a batch of images using show_images
    show_images(self.batch[0][:max_n], **kwargs)

# %% ../nbs/14_minimalai-augment.ipynb 41
class CapturePreds(Callback):
    """
    Callback to capture inputs, predictions, and targets during the training process.
    """

    def before_fit(self, learner):
        """
        Prepare lists to store inputs, predictions, and targets before the training starts.

        Args:
        - learner (Learner): The learner object.
        """
        self.all_inps, self.all_preds, self.all_targs = [], [], []

    def after_batch(self, learner):
        """
        Capture inputs, predictions, and targets after each batch.

        Args:
        - learner (Learner): The learner object.
        """
        self.all_inps.append(to_cpu(learner.batch[0]))
        self.all_preds.append(to_cpu(learner.predictions))
        self.all_targs.append(to_cpu(learner.batch[1]))

    def after_fit(self, learner):
        """
        Concatenate the captured inputs, predictions, and targets after training completes.

        Args:
        - learner (Learner): The learner object.
        """
        self.all_preds, self.all_targs, self.all_inps = map(torch.cat, [self.all_preds, self.all_targs, self.all_inps])

# %% ../nbs/14_minimalai-augment.ipynb 42
@fc.patch
def capture_preds(self: Learner, callbacks=None, inps=False):
    """
    Capture predictions, targets, and optionally inputs during the evaluation.

    Args:
    - self (Learner): The learner instance.
    - callbacks (list or Callback): Additional callbacks to be applied during evaluation.
    - inps (bool): Whether to include inputs in the result.

    Returns:
    - tuple: Captured predictions and targets. If `inps` is `True`, also includes captured inputs.
    """
    # Create an instance of CapturePreds callback
    cp = CapturePreds()
    
    # Fit the model for one epoch with the CapturePreds callback and additional callbacks
    self.fit(1, train=False, callbacks=[cp] + fc.L(callbacks))
    
    # Get the captured predictions and targets
    res = cp.all_preds, cp.all_targs
    
    # Optionally include captured inputs in the result
    if inps:
        res = res + (cp.all_inps,)
    
    return res

# %% ../nbs/14_minimalai-augment.ipynb 57
def random_erasing(x: torch.Tensor, erase_pct: float, mean: float, std: float, min_val: float, max_val: float):
    """
    Randomly erase a portion of the input tensor x.

    Args:
    - x (Tensor): Input tensor.
    - erase_pct (float): Percentage of the image area to be erased.
    - mean (float): Mean of the normal distribution for random initialization.
    - std (float): Standard deviation of the normal distribution for random initialization.
    - min_val (float): Minimum value for clamping.
    - max_val (float): Maximum value for clamping.
    """
    # Calculate the size and starting coordinates of the random erase region
    erase_width = int(erase_pct * x.shape[-2])  # Width of the erasing region
    erase_height = int(erase_pct * x.shape[-1])  # Height of the erasing region
    start_x = int(random.random() * (1 - erase_pct) * x.shape[-2])  # Starting coordinate along the x-axis
    start_y = int(random.random() * (1 - erase_pct) * x.shape[-1])  # Starting coordinate along the y-axis
    
    # Initialize the random erase region with a normal distribution
    init.normal_(x[:, :, start_x:start_x + erase_width, start_y:start_y + erase_height], mean=mean, std=std)
    
    # Clamp the values in the tensor to the specified range
    x.clamp_(min_val, max_val)

# %% ../nbs/14_minimalai-augment.ipynb 60
def random_erase(x: torch.Tensor, erase_pct: float = 0.2, max_erases: int = 4):
    """
    Apply random erasing to the input tensor x.

    Args:
    - x (Tensor): Input tensor.
    - erase_pct (float): Percentage of the image area to be erased in each iteration.
    - max_erases (int): Maximum number of random erasing operations to apply.

    Returns:
    - Tensor: The input tensor with random erasing applied.
    """
    # Calculate the mean, standard deviation, minimum, and maximum values of the input tensor
    mean_value = x.mean()
    std_value = x.std()
    min_value = x.min()
    max_value = x.max()

    # Generate a random number of erasing operations to apply
    num_erases = random.randint(0, max_erases)

    # Apply random erasing to the input tensor for the generated number of times
    for _ in range(num_erases):
        random_erasing(x, erase_pct, mean_value, std_value, min_value, max_value)

    # Return the input tensor with random erasing applied
    return x

# %% ../nbs/14_minimalai-augment.ipynb 62
class RandomErasing(nn.Module):
    def __init__(self, erase_pct=0.2, max_erases=4):
        """
        A module for applying random erasing to input tensors.

        Args:
        - erase_pct (float): Percentage of the image area to be erased in each iteration.
        - max_erases (int): Maximum number of random erasing operations to apply.
        """
        super().__init__()
        self.erase_pct = erase_pct
        self.max_erases = max_erases

    def forward(self, x):
        """
        Forward pass of the RandomErasing module.

        Args:
        - x (Tensor): Input tensor.

        Returns:
        - Tensor: The input tensor with random erasing applied.
        """
        # Apply random erasing to the input tensor
        return random_erase(x, self.erase_pct, self.max_erases)

# %% ../nbs/14_minimalai-augment.ipynb 71
def random_copy1(x: torch.Tensor, pct: float):
    """
    Randomly copy a portion of the input tensor x to another portion.

    Args:
    - x (Tensor): Input tensor.
    - pct (float): Percentage of the image area to be copied.

    Returns:
    - None: The input tensor x is modified in-place.
    """
    # Calculate the size and starting coordinates of two random copy regions
    copy_size_x = int(pct * x.shape[-2])  # Size of the copy along the x-axis
    copy_size_y = int(pct * x.shape[-1])  # Size of the copy along the y-axis
    start_x1 = int(random.random() * (1 - pct) * x.shape[-2])  # Starting coordinate along the x-axis for copy 1
    start_y1 = int(random.random() * (1 - pct) * x.shape[-1])  # Starting coordinate along the y-axis for copy 1
    start_x2 = int(random.random() * (1 - pct) * x.shape[-2])  # Starting coordinate along the x-axis for copy 2
    start_y2 = int(random.random() * (1 - pct) * x.shape[-1])  # Starting coordinate along the y-axis for copy 2
    
    # Perform the random copy operation
    x[:, :, start_x1:start_x1 + copy_size_x, start_y1:start_y1 + copy_size_y] = \
        x[:, :, start_x2:start_x2 + copy_size_x, start_y2:start_y2 + copy_size_y]

# %% ../nbs/14_minimalai-augment.ipynb 73
def random_copy(x: torch.Tensor, copy_pct: float = 0.2, max_copies: int = 4):
    """
    Apply random copying to the input tensor x.

    Args:
    - x (Tensor): Input tensor.
    - copy_pct (float): Percentage of the image area to be copied in each iteration.
    - max_copies (int): Maximum number of random copying operations to apply.

    Returns:
    - Tensor: The input tensor with random copying applied.
    """
    # Generate a random number of copying operations to apply
    num_copies = random.randint(0, max_copies)

    # Apply random copying to the input tensor for the generated number of times
    for _ in range(num_copies):
        random_copy1(x, copy_pct)

    # Return the input tensor with random copying applied
    return x

# %% ../nbs/14_minimalai-augment.ipynb 75
class RandomCopy(nn.Module):
    def __init__(self, copy_pct=0.2, max_copies=4):
        """
        A module for applying random copying to input tensors.

        Args:
        - copy_pct (float): Percentage of the image area to be copied in each iteration.
        - max_copies (int): Maximum number of random copying operations to apply.
        """
        super().__init__()
        self.copy_pct = copy_pct
        self.max_copies = max_copies

    def forward(self, x):
        """
        Forward pass of the RandomCopy module.

        Args:
        - x (Tensor): Input tensor.

        Returns:
        - Tensor: The input tensor with random copying applied.
        """
        # Apply random copying to the input tensor
        return random_copy(x, self.copy_pct, self.max_copies)
