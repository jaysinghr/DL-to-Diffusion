# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/07_minimalai-convolutions.ipynb.

# %% auto 0
__all__ = ['default_device', 'conv_layer', 'move_data_to_device', 'collate_data_on_device']

# %% ../nbs/07_minimalai-convolutions.ipynb 3
import torch
from torch import nn

from torch.utils.data import default_collate
from typing import Mapping

from .training import *
from .datasets import *

# %% ../nbs/07_minimalai-convolutions.ipynb 78
def conv_layer(input_channels, output_channels, kernel_size=3, stride=2, apply_activation=True):
    """
    Create a convolutional layer with optional activation.

    Args:
    - input_channels (int): Number of input channels for the convolutional layer.
    - output_channels (int): Number of output channels (filters) for the convolutional layer.
    - kernel_size (int): Size of the convolutional kernel (filter) (default: 3).
    - stride (int): Stride of the convolution operation (default: 2).
    - apply_activation (bool): Whether to apply ReLU activation after the convolution (default: True).

    Returns:
    - torch.nn.Module: The created convolutional layer (with optional activation).
    """
    # Create the convolutional layer with specified parameters
    conv_layer = nn.Conv2d(in_channels=input_channels, out_channels=output_channels,
                           kernel_size=kernel_size, stride=stride, padding=kernel_size//2)
    
    # Apply ReLU activation if specified
    if apply_activation:
        conv_layer = nn.Sequential(conv_layer, nn.ReLU())
    
    return conv_layer


# %% ../nbs/07_minimalai-convolutions.ipynb 83
# Determine the default device based on availability (mps, cuda, cpu)
default_device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'

def move_data_to_device(data, device=default_device):
    """
    Move input data tensors or nested collections of tensors to the specified device.

    Args:
    - data (torch.Tensor or Mapping or Iterable): Input data tensors or nested collections of tensors.
    - device (str): Target device to move the data to (default: determined based on availability).

    Returns:
    - torch.Tensor or Mapping or Iterable: Data tensors or nested collections of tensors moved to the specified device.
    """
    # If input is a single tensor, move it to the specified device
    if isinstance(data, torch.Tensor):
        return data.to(device)
    # If input is a mapping (e.g., dictionary), move each value to the specified device
    if isinstance(data, Mapping):
        return {key: value.to(device) for key, value in data.items()}
    # If input is an iterable (e.g., list), recursively move each element to the specified device
    return type(data)(move_data_to_device(item, device) for item in data)

def collate_data_on_device(batch, device=default_device):
    """
    Collate a batch of data and move it to the specified device.

    Args:
    - batch (Iterable): Batch of data to collate.
    - device (str): Target device to move the collated batch to (default: determined based on availability).

    Returns:
    - torch.Tensor or Mapping or Iterable: Collated batch of data moved to the specified device.
    """
    # Collate the batch of data and move it to the specified device
    return move_data_to_device(default_collate(batch), device)
